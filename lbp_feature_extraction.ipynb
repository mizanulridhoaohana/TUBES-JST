{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from skimage import feature\n",
    "from skimage.feature import graycomatrix, graycoprops\n",
    "from skimage import io, color, img_as_ubyte\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report, f1_score, recall_score, precision_score\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local Binary Pattern"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load data success!\n",
      "(1790, 256, 256)\n",
      "(1432, 256, 256)\n",
      "(358, 256, 256)\n",
      "(1432,)\n",
      "(358,)\n"
     ]
    }
   ],
   "source": [
    "def read_images_from_folder(folder_path):\n",
    "    images = []\n",
    "    labels = []\n",
    "\n",
    "    for subfolder in os.listdir(folder_path):\n",
    "        subfolder_path = os.path.join(folder_path, subfolder)\n",
    "        if os.path.isdir(subfolder_path):\n",
    "            label = subfolder  # Use the subfolder name as the label\n",
    "            for fn in os.listdir(subfolder_path):\n",
    "                if fn.endswith('.jpg'):\n",
    "                    img_path = os.path.join(subfolder_path, fn)\n",
    "                    im = Image.open(img_path).convert('L')\n",
    "                    data = np.array(im)\n",
    "                    images.append(data)\n",
    "                    labels.append(label)\n",
    "\n",
    "    return images, labels\n",
    "\n",
    "# Load images and labels from the 'resize_data' \n",
    "data_folder = './resize_data'\n",
    "images, labels = read_images_from_folder(data_folder)\n",
    "print('Load data success!')\n",
    "\n",
    "X = np.array(images)\n",
    "print(X.shape)\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(labels)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "radius = 2\n",
    "n_point = radius * 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lbp_texture(train_data, test_data):\n",
    "    max_bins_train = 0\n",
    "    max_bins_test = 0\n",
    "\n",
    "    for i in range(len(train_data)):\n",
    "        lbp = feature.local_binary_pattern(train_data[i], n_point, radius, 'default')\n",
    "        max_bins_train = max(max_bins_train, int(lbp.max()) + 1)\n",
    "\n",
    "    for i in range(len(test_data)):\n",
    "        lbp = feature.local_binary_pattern(test_data[i], n_point, radius, 'default')\n",
    "        max_bins_test = max(max_bins_test, int(lbp.max()) + 1)\n",
    "\n",
    "    train_hist = np.zeros((len(train_data), max_bins_train))\n",
    "    test_hist = np.zeros((len(test_data), max_bins_test))\n",
    "\n",
    "    for i in range(len(train_data)):\n",
    "        lbp = feature.local_binary_pattern(train_data[i], n_point, radius, 'default')\n",
    "        train_hist[i], _ = np.histogram(lbp, bins=max_bins_train, density=True)\n",
    "\n",
    "    for i in range(len(test_data)):\n",
    "        lbp = feature.local_binary_pattern(test_data[i], n_point, radius, 'default')\n",
    "        test_hist[i], _ = np.histogram(lbp, bins=max_bins_test, density=True)\n",
    "\n",
    "    return train_hist, test_hist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mizanul/Documents/code/.venv/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.9636871508379888\n",
      "Test Accuracy: 0.8491620111731844\n",
      "Precision: 0.8502792586951002\n",
      "Recall: 0.8463227911646587\n",
      "F1 Score: 0.8476211495412556\n",
      "Overall Accuracy: 0.8491620111731844\n",
      "Overall Accuracy:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.89      0.86       192\n",
      "           1       0.86      0.81      0.83       166\n",
      "\n",
      "    accuracy                           0.85       358\n",
      "   macro avg       0.85      0.85      0.85       358\n",
      "weighted avg       0.85      0.85      0.85       358\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test = lbp_texture(X_train, X_test)\n",
    "\n",
    "# Create and train an MLP classifier\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(100, 50), max_iter=200)\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = mlp.predict(X_test)\n",
    "\n",
    "# Evaluate the MLP classifier\n",
    "train_accuracy = mlp.score(X_train, y_train)\n",
    "test_accuracy = mlp.score(X_test, y_test)\n",
    "precision = precision_score(y_test, y_pred, average='macro')\n",
    "recall = recall_score(y_test, y_pred, average='macro')\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "classify_report = classification_report(y_test, y_pred)\n",
    "\n",
    "\n",
    "print(f\"Training Accuracy: {train_accuracy}\")\n",
    "print(f\"Test Accuracy: {test_accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(f\"\\nOverall Accuracy: {classify_report}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP model saved as ./model/mlp_lbp_model.pkl\n"
     ]
    }
   ],
   "source": [
    "# Save the trained MLP model to a file\n",
    "model_filename = './model/mlp_lbp_model.pkl'\n",
    "joblib.dump(mlp, model_filename)\n",
    "\n",
    "print(f\"MLP model saved as {model_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
