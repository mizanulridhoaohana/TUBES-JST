{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from skimage.feature import graycomatrix, graycoprops\n",
    "from skimage import io, color, img_as_ubyte\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local Binary Pattern"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load data success!\n",
      "(1790, 256, 256)\n",
      "(1432, 256, 256)\n",
      "(358, 256, 256)\n",
      "(1432,)\n",
      "(358,)\n"
     ]
    }
   ],
   "source": [
    "def read_images_from_folder(folder_path):\n",
    "    images = []\n",
    "    labels = []\n",
    "\n",
    "    for subfolder in os.listdir(folder_path):\n",
    "        subfolder_path = os.path.join(folder_path, subfolder)\n",
    "        if os.path.isdir(subfolder_path):\n",
    "            label = subfolder  # Use the subfolder name as the label\n",
    "            for fn in os.listdir(subfolder_path):\n",
    "                if fn.endswith('.jpg'):\n",
    "                    img_path = os.path.join(subfolder_path, fn)\n",
    "                    im = Image.open(img_path).convert('L')\n",
    "                    data = np.array(im)\n",
    "                    images.append(data)\n",
    "                    labels.append(label)\n",
    "\n",
    "    return images, labels\n",
    "\n",
    "# Load images and labels from the 'resize_data' folder structure\n",
    "data_folder = './resize_data'\n",
    "images, labels = read_images_from_folder(data_folder)\n",
    "print('Load data success!')\n",
    "\n",
    "X = np.array(images)\n",
    "print(X.shape)\n",
    "\n",
    "# Encode labels (CORROSION, NOCORROSION) to numerical values\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(labels)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "radius = 2\n",
    "n_point = radius * 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lbp_texture(train_data, test_data):\n",
    "    max_bins_train = 0\n",
    "    max_bins_test = 0\n",
    "\n",
    "    for i in range(len(train_data)):\n",
    "        lbp = feature.local_binary_pattern(train_data[i], n_point, radius, 'default')\n",
    "        max_bins_train = max(max_bins_train, int(lbp.max()) + 1)\n",
    "\n",
    "    for i in range(len(test_data)):\n",
    "        lbp = feature.local_binary_pattern(test_data[i], n_point, radius, 'default')\n",
    "        max_bins_test = max(max_bins_test, int(lbp.max()) + 1)\n",
    "\n",
    "    train_hist = np.zeros((len(train_data), max_bins_train))\n",
    "    test_hist = np.zeros((len(test_data), max_bins_test))\n",
    "\n",
    "    for i in range(len(train_data)):\n",
    "        lbp = feature.local_binary_pattern(train_data[i], n_point, radius, 'default')\n",
    "        train_hist[i], _ = np.histogram(lbp, bins=max_bins_train, density=True)\n",
    "\n",
    "    for i in range(len(test_data)):\n",
    "        lbp = feature.local_binary_pattern(test_data[i], n_point, radius, 'default')\n",
    "        test_hist[i], _ = np.histogram(lbp, bins=max_bins_test, density=True)\n",
    "\n",
    "    return train_hist, test_hist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mizanul/Documents/code/.venv/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.9636871508379888\n",
      "Test Accuracy: 0.8491620111731844\n",
      "Precision: 0.8502792586951002\n",
      "Recall: 0.8463227911646587\n",
      "F1 Score: 0.8476211495412556\n",
      "Overall Accuracy: 0.8491620111731844\n",
      "Overall Accuracy:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.89      0.86       192\n",
      "           1       0.86      0.81      0.83       166\n",
      "\n",
      "    accuracy                           0.85       358\n",
      "   macro avg       0.85      0.85      0.85       358\n",
      "weighted avg       0.85      0.85      0.85       358\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from skimage import feature\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score\n",
    "from PIL import Image\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test = lbp_texture(X_train, X_test)\n",
    "\n",
    "# Create and train an MLP classifier\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(100, 50), max_iter=200)\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = mlp.predict(X_test)\n",
    "\n",
    "# Evaluate the MLP classifier\n",
    "train_accuracy = mlp.score(X_train, y_train)\n",
    "test_accuracy = mlp.score(X_test, y_test)\n",
    "precision = precision_score(y_test, y_pred, average='macro')\n",
    "recall = recall_score(y_test, y_pred, average='macro')\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "classify_report = classification_report(y_test, y_pred)\n",
    "\n",
    "\n",
    "print(f\"Training Accuracy: {train_accuracy}\")\n",
    "print(f\"Test Accuracy: {test_accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(f\"\\nOverall Accuracy: {classify_report}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP model saved as ./model/mlp_lbp_model.pkl\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the trained MLP model to a file\n",
    "model_filename = './model/mlp_lbp_model.pkl'\n",
    "joblib.dump(mlp, model_filename)\n",
    "\n",
    "print(f\"MLP model saved as {model_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'model/mlp_lbp_model.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/mizanul/Documents/code/TUBES-JST/feature_extraction.ipynb Cell 22\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/mizanul/Documents/code/TUBES-JST/feature_extraction.ipynb#X26sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39m# Call the LBP function on the single image\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/mizanul/Documents/code/TUBES-JST/feature_extraction.ipynb#X26sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m lbp_features \u001b[39m=\u001b[39m lbp_texture(data)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/mizanul/Documents/code/TUBES-JST/feature_extraction.ipynb#X26sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m loaded_model \u001b[39m=\u001b[39m joblib\u001b[39m.\u001b[39;49mload(\u001b[39m'\u001b[39;49m\u001b[39mmodel/mlp_lbp_model.pkl\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/mizanul/Documents/code/TUBES-JST/feature_extraction.ipynb#X26sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m prediction \u001b[39m=\u001b[39m loaded_model\u001b[39m.\u001b[39mpredict([lbp_features])\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/mizanul/Documents/code/TUBES-JST/feature_extraction.ipynb#X26sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m \u001b[39mprint\u001b[39m(prediction)\n",
      "File \u001b[0;32m~/Documents/code/.venv/lib/python3.10/site-packages/joblib/numpy_pickle.py:650\u001b[0m, in \u001b[0;36mload\u001b[0;34m(filename, mmap_mode)\u001b[0m\n\u001b[1;32m    648\u001b[0m         obj \u001b[39m=\u001b[39m _unpickle(fobj)\n\u001b[1;32m    649\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 650\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m(filename, \u001b[39m'\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m    651\u001b[0m         \u001b[39mwith\u001b[39;00m _read_fileobject(f, filename, mmap_mode) \u001b[39mas\u001b[39;00m fobj:\n\u001b[1;32m    652\u001b[0m             \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(fobj, \u001b[39mstr\u001b[39m):\n\u001b[1;32m    653\u001b[0m                 \u001b[39m# if the returned file object is a string, this means we\u001b[39;00m\n\u001b[1;32m    654\u001b[0m                 \u001b[39m# try to load a pickle file generated with an version of\u001b[39;00m\n\u001b[1;32m    655\u001b[0m                 \u001b[39m# Joblib so we load it with joblib compatibility function.\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'model/mlp_lbp_model.pkl'"
     ]
    }
   ],
   "source": [
    "from skimage import feature\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "def lbp_texture(image):\n",
    "    # Perform LBP feature extraction on a single image\n",
    "    lbp = feature.local_binary_pattern(image, n_point, radius, 'default')\n",
    "    max_bins = int(lbp.max() + 1)\n",
    "    hist, _ = np.histogram(lbp, bins=max_bins, density=True)\n",
    "    return hist\n",
    "\n",
    "# Load and preprocess a single image\n",
    "image_path = './resize_data/NOCORROSION/01a5aee1ab.jpg'\n",
    "im = Image.open(image_path).convert('L')\n",
    "data = np.array(im)\n",
    "\n",
    "# Define LBP parameters\n",
    "radius = 2\n",
    "n_point = radius * 8\n",
    "\n",
    "# Call the LBP function on the single image\n",
    "lbp_features = lbp_texture(data)\n",
    "\n",
    "loaded_model = joblib.load('model/mlp_lbp_model.pkl')\n",
    "prediction = loaded_model.predict([lbp_features])\n",
    "print(prediction)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
